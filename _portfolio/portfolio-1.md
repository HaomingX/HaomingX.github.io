---
title: "Relearn: Machine Unlearning Framework for LLMs"
excerpt: "A novel framework for machine unlearning in large language models that enables effective removal of specific knowledge while preserving model performance through a learning-based approach.<br/><img src='/images/500x300.png'>"
collection: portfolio
---

## Overview

**Relearn** is a comprehensive framework for machine unlearning in large language models. The project addresses the critical need for removing specific knowledge from trained models while maintaining overall performanceâ€”essential for privacy compliance, model refinement, and ethical AI deployment.

## Key Features

- **Dual-phase Unlearning**: Combines targeted knowledge removal with performance preservation
- **Scalable Architecture**: Applicable to various LLM architectures (GPT, BERT, T5, etc.)
- **Benchmark Suite**: Comprehensive evaluation metrics for unlearning effectiveness

## Technical Highlights

- Developed novel learning-based unlearning methods that reduce unwanted knowledge retention by 60%+
- Maintained task performance within 2% of original models
- Published at top-tier venues with open-source implementation

## Impact

This work has implications for:
- Privacy-preserving machine learning
- GDPR and data protection compliance
- Model refinement and knowledge management
- Responsible AI deployment

## Publications

- **Relearn: Unlearning via Learning for Large Language Models** (2025)
- **ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging** (2025)
